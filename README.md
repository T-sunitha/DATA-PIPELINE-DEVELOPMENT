## RECOMMENDATION SYSTEM
A data pipeline is a series of automated steps that collect, process, and move data from one system to another, enabling data analysis, modeling, or reporting.
In machine learning and analytics projects, pipelines ensure reproducibility, scalability, and automation
-Tools are used in data science 
Ingestion-	pandas, requests, BeautifulSoup, boto3
Preprocessing-	pandas, numpy, pyjanitor
Transformation- scikit-learn, featuretools
Modeling-	scikit-learn, xgboost, tensorflow
Storage-	SQLAlchemy, Parquet, MongoDB
Deployment-	Flask, FastAPI, Docker
Automation-	Airflow, Prefect, Luigi
Monitoring-	MLflow, Prometheus, Grafana

**Internship Information**
Company: IT CODTECH SOLUTIONS PVT. LTD
Name : TUMMAPUDI SUNITHA
Intern ID :CT06DF424
Domain: Data Science
Duration: 6 Weeks
Mentor: Neela Santhosh Kumar

## **Task Description **

Data Pipeline Development refers to the design and implementation of a structured flow of processes 
enable the collection, transformation, validation and storage of data
for further analysis, reporting, or machine learning tasks.
A well-designed data pipeline automates the movement and processing of data from raw input to usable 
output, ensuring data quality, reproducibility, and scalability across environments.

## Technologies Used

Data creation-	pandas
Missing value handling-	SimpleImputer
Feature scaling	-StandardScaler
One-hot encoding	-OneHotEncoder
Combined processing	-ColumnTransformer
Pipelining	-Pipeline
